"""
Azure Container Apps å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ Ã— Azure OpenAI Responses API + MCP ã‚µãƒ³ãƒ—ãƒ«

Azure OpenAI ã® Responses API ã¨ MCP (Model Context Protocol) ã‚’çµ„ã¿åˆã‚ã›ã€
å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒ„ãƒ¼ãƒ«ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚
Responses API ãŒ MCP ã‚µãƒ¼ãƒãƒ¼ã¨ç›´æ¥é€šä¿¡ã—ã€GPT ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã«å¿œã˜ã¦
Python ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚’è‡ªå‹•çš„ã«è¡Œã„ã¾ã™ã€‚
"""

import os
import sys

from dotenv import load_dotenv
from openai import AzureOpenAI


def create_mcp_tool(mcp_endpoint: str, api_key: str) -> dict:
    """MCP ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’ä½œæˆã™ã‚‹"""
    return {
        "type": "mcp",
        "server_label": "aca-python-sessions",
        "server_url": mcp_endpoint,
        "headers": {
            "x-ms-apikey": api_key,
        },
        "require_approval": "never",
    }


SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€"
    "å¿…è¦ã«å¿œã˜ã¦ MCP ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ Python ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚"
    "è¨ˆç®—ã‚„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒå¿…è¦ãªå ´åˆã¯ã€ã¾ãš launchPythonEnvironment ã§ç’°å¢ƒã‚’èµ·å‹•ã—ã€"
    "æ¬¡ã« runPythonCodeInRemoteEnvironment ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    "ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œçµæœã¯å¿…ãš print() ã§å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
)


def chat_with_mcp(
    client: AzureOpenAI,
    model: str,
    mcp_tool: dict,
    user_message: str,
) -> str:
    """Responses API ã§ MCP ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã™ã‚‹"""
    print(f"\n{'='*60}")
    print(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_message}")
    print(f"{'='*60}")

    response = client.responses.create(
        model=model,
        instructions=SYSTEM_PROMPT,
        tools=[mcp_tool],
        input=user_message,
    )

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡ºåŠ›ã‚’è¡¨ç¤º
    final_text = ""
    for item in response.output:
        if item.type == "mcp_list_tools":
            tool_names = [t.name for t in item.tools]
            print(f"\nğŸ” MCP ãƒ„ãƒ¼ãƒ«æ¤œå‡º: {', '.join(tool_names)}")
        elif item.type == "mcp_call":
            print(f"\nğŸ”§ MCP ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—: {item.name}")
            print(f"   ã‚µãƒ¼ãƒãƒ¼: {item.server_label}")
            if hasattr(item, "arguments") and item.arguments:
                args_preview = item.arguments[:200]
                print(f"   å¼•æ•°: {args_preview}{'...' if len(item.arguments) > 200 else ''}")
        elif item.type == "message":
            for content in item.content:
                if content.type == "output_text":
                    print(f"\nğŸ¤– GPT: {content.text}")
                    final_text += content.text

    return final_text


def run_demo(
    client: AzureOpenAI,
    model: str,
    mcp_tool: dict,
):
    """ãƒ‡ãƒ¢ç”¨ã®è³ªå•ã‚’å®Ÿè¡Œã™ã‚‹"""
    examples = [
        "2ã®20ä¹—ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„",
        "1ã‹ã‚‰100ã¾ã§ã®ç´ æ•°ã‚’ã™ã¹ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„",
        "pandasã‚’ä½¿ã£ã¦ã€æ—¥æœ¬ã®ä¸»è¦5éƒ½å¸‚ï¼ˆæ±äº¬ã€å¤§é˜ªã€åå¤å±‹ã€æœ­å¹Œã€ç¦å²¡ï¼‰ã®äººå£ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã€äººå£ã®å¤šã„é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„",
    ]

    for example in examples:
        chat_with_mcp(
            client=client,
            model=model,
            mcp_tool=mcp_tool,
            user_message=example,
        )


def run_interactive(
    client: AzureOpenAI,
    model: str,
    mcp_tool: dict,
):
    """å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã™ã‚‹"""
    print("\nğŸ’¬ å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚'quit' ã¾ãŸã¯ 'exit' ã§çµ‚äº†ã—ã¾ã™ã€‚")
    print("   è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚GPT ãŒ MCP çµŒç”±ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦å›ç­”ã—ã¾ã™ã€‚\n")

    while True:
        try:
            user_input = input("ã‚ãªãŸ: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
            break

        if not user_input:
            continue
        if user_input.lower() in ("quit", "exit", "q"):
            print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
            break

        chat_with_mcp(
            client=client,
            model=model,
            mcp_tool=mcp_tool,
            user_message=user_input,
        )


def main():
    # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    load_dotenv()

    # ç’°å¢ƒå¤‰æ•°ã®å–å¾—
    mcp_endpoint = os.getenv("MCP_ENDPOINT")
    mcp_api_key = os.getenv("MCP_API_KEY")
    azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    azure_openai_key = os.getenv("AZURE_OPENAI_API_KEY")
    azure_openai_model = os.getenv("AZURE_OPENAI_MODEL", "gpt-4o")

    # å¿…é ˆç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not mcp_endpoint:
        print("âŒ MCP_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    if not mcp_api_key:
        print("âŒ MCP_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    if not azure_openai_endpoint:
        print("âŒ AZURE_OPENAI_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    if not azure_openai_key:
        print("âŒ AZURE_OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ï¼ˆResponses API å¯¾å¿œãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰
    client = AzureOpenAI(
        azure_endpoint=azure_openai_endpoint,
        api_key=azure_openai_key,
        api_version="2025-04-01-preview",
    )

    # MCP ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’ä½œæˆ
    mcp_tool = create_mcp_tool(mcp_endpoint, mcp_api_key)

    print(f"ğŸš€ Azure OpenAI Responses API + MCP ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ğŸ”— Azure OpenAI ãƒ¢ãƒ‡ãƒ«: {azure_openai_model}")
    print(f"ğŸŒ MCP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {mcp_endpoint[:60]}...")

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ¤å®š
    interactive = "--interactive" in sys.argv or "-i" in sys.argv

    if interactive:
        run_interactive(
            client=client,
            model=azure_openai_model,
            mcp_tool=mcp_tool,
        )
    else:
        run_demo(
            client=client,
            model=azure_openai_model,
            mcp_tool=mcp_tool,
        )

    print(f"\n{'='*60}")
    print("âœ… å®Œäº†ï¼")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
