"""
Azure Container Apps å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ Ã— Azure OpenAI ã‚µãƒ³ãƒ—ãƒ« (GPT Code Interpreter)

Azure OpenAI ã® Function Calling ã‚’ä½¿ã„ã€å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’
ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒ„ãƒ¼ãƒ«ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚
GPT ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã«å¿œã˜ã¦ Python ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€
å‹•çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ç’°å¢ƒã§å®‰å…¨ã«å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import json
import os
import sys
import uuid

import httpx
from azure.identity import DefaultAzureCredential
from dotenv import load_dotenv
from openai import AzureOpenAI


def get_session_headers() -> dict:
    """Dynamic Sessions ç”¨ã®èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—ã™ã‚‹"""
    credential = DefaultAzureCredential()
    token = credential.get_token("https://dynamicsessions.io/.default")
    return {
        "Authorization": f"Bearer {token.token}",
        "Content-Type": "application/json",
    }


def execute_code_in_session(pool_endpoint: str, code: str, session_id: str) -> str:
    """Dynamic Sessions ã§ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹"""
    headers = get_session_headers()
    url = f"{pool_endpoint}/executions?identifier={session_id}&api-version=2025-10-02-preview"
    payload = {
        "codeInputType": "inline",
        "executionType": "synchronous",
        "code": code,
        "timeoutInSeconds": 60,
    }
    with httpx.Client() as client:
        print(f"   ğŸŒ Dynamic Sessions API å‘¼ã³å‡ºã—ä¸­...")
        print(f"      POST {url[:80]}...")
        response = client.post(url, headers=headers, json=payload)
        response.raise_for_status()
        result = response.json()

    status = result.get("status", "Unknown")
    exec_time = result.get("result", {}).get("executionTimeInMilliseconds", "N/A")
    print(f"   âœ… Dynamic Sessions å®Ÿè¡Œå®Œäº† (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}, å®Ÿè¡Œæ™‚é–“: {exec_time}ms)")

    stdout = result.get("result", {}).get("stdout", "")
    stderr = result.get("result", {}).get("stderr", "")
    execution_result = result.get("result", {}).get("executionResult", "")

    output_parts = []
    if stdout:
        output_parts.append(stdout)
    if execution_result:
        output_parts.append(str(execution_result))
    if stderr:
        output_parts.append(f"[stderr]: {stderr}")

    return "\n".join(output_parts).strip() if output_parts else "(å®Ÿè¡Œå®Œäº†ãƒ»å‡ºåŠ›ãªã—)"


# Azure OpenAI ã«ç™»éŒ²ã™ã‚‹ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆFunction Callingï¼‰
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "execute_python_code",
            "description": (
                "ã‚¯ãƒ©ã‚¦ãƒ‰ä¸Šã®å®‰å…¨ãªã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§ Python ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚"
                "è¨ˆç®—ã€ãƒ‡ãƒ¼ã‚¿åˆ†æã€ã‚°ãƒ©ãƒ•ä½œæˆãªã©ã«ä½¿ç”¨ã§ãã¾ã™ã€‚"
                "pandas, numpy, matplotlib, scipy ãªã©ã®ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "å®Ÿè¡Œã™ã‚‹ Python ã‚³ãƒ¼ãƒ‰",
                    }
                },
                "required": ["code"],
            },
        },
    }
]

SYSTEM_PROMPT = (
    "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ã€"
    "å¿…è¦ã«å¿œã˜ã¦ Python ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚"
    "è¨ˆç®—ã‚„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãŒå¿…è¦ãªå ´åˆã¯ã€execute_python_code ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
    "ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œçµæœã¯å¿…ãš print() ã§å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
)


def chat_with_code_execution(
    client: AzureOpenAI,
    model: str,
    pool_endpoint: str,
    user_message: str,
    session_id: str,
) -> str:
    """Azure OpenAI ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã€å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹"""
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_message},
    ]

    print(f"\n{'='*60}")
    print(f"ğŸ“ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_message}")
    print(f"{'='*60}")

    response = client.chat.completions.create(
        model=model,
        messages=messages,
        tools=TOOLS,
        tool_choice="auto",
    )

    assistant_message = response.choices[0].message

    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹å ´åˆã€å®Ÿè¡Œã—ã¦çµæœã‚’è¿”ã™ï¼ˆè¤‡æ•°å›ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã«å¯¾å¿œï¼‰
    while assistant_message.tool_calls:
        messages.append(assistant_message)

        for tool_call in assistant_message.tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)

            if function_name == "execute_python_code":
                code = arguments["code"]
                print(f"\nğŸ”§ GPT ãŒ Function Calling ã§ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã‚’è¦æ±‚ã—ã¾ã—ãŸ:")
                print(f"   é–¢æ•°å: {function_name}")
                print(f"```python\n{code}\n```")

                try:
                    result = execute_code_in_session(
                        pool_endpoint, code, session_id
                    )
                    print(f"\nğŸ“Š å®Ÿè¡Œçµæœ:\n{result}")
                except Exception as e:
                    result = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                    print(f"\nâŒ {result}")

                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result,
                    }
                )

        response = client.chat.completions.create(
            model=model,
            messages=messages,
            tools=TOOLS,
            tool_choice="auto",
        )
        assistant_message = response.choices[0].message

    final_answer = assistant_message.content
    print(f"\nğŸ¤– GPT: {final_answer}")
    return final_answer


def run_demo(
    client: AzureOpenAI,
    model: str,
    pool_endpoint: str,
    session_id: str,
):
    """ãƒ‡ãƒ¢ç”¨ã®è³ªå•ã‚’å®Ÿè¡Œã™ã‚‹"""
    examples = [
        "2ã®20ä¹—ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„",
        "1ã‹ã‚‰100ã¾ã§ã®ç´ æ•°ã‚’ã™ã¹ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„",
        "pandasã‚’ä½¿ã£ã¦ã€æ—¥æœ¬ã®ä¸»è¦5éƒ½å¸‚ï¼ˆæ±äº¬ã€å¤§é˜ªã€åå¤å±‹ã€æœ­å¹Œã€ç¦å²¡ï¼‰ã®äººå£ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã€äººå£ã®å¤šã„é †ã«ã‚½ãƒ¼ãƒˆã—ã¦è¡¨ç¤ºã—ã¦ãã ã•ã„",
    ]

    for example in examples:
        chat_with_code_execution(
            client=client,
            model=model,
            pool_endpoint=pool_endpoint,
            user_message=example,
            session_id=session_id,
        )


def run_interactive(
    client: AzureOpenAI,
    model: str,
    pool_endpoint: str,
    session_id: str,
):
    """å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã™ã‚‹"""
    print("\nğŸ’¬ å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚'quit' ã¾ãŸã¯ 'exit' ã§çµ‚äº†ã—ã¾ã™ã€‚")
    print("   è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚GPT ãŒå¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦å›ç­”ã—ã¾ã™ã€‚\n")

    while True:
        try:
            user_input = input("ã‚ãªãŸ: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n\nğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
            break

        if not user_input:
            continue
        if user_input.lower() in ("quit", "exit", "q"):
            print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚")
            break

        chat_with_code_execution(
            client=client,
            model=model,
            pool_endpoint=pool_endpoint,
            user_message=user_input,
            session_id=session_id,
        )


def main():
    # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    load_dotenv()

    # ç’°å¢ƒå¤‰æ•°ã®å–å¾—
    pool_endpoint = os.getenv("POOL_ENDPOINT")
    azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    azure_openai_key = os.getenv("AZURE_OPENAI_API_KEY")
    azure_openai_model = os.getenv("AZURE_OPENAI_MODEL", "gpt-4o")

    # å¿…é ˆç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯
    if not pool_endpoint:
        print("âŒ POOL_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    if not azure_openai_endpoint:
        print("âŒ AZURE_OPENAI_ENDPOINT ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    if not azure_openai_key:
        print("âŒ AZURE_OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    client = AzureOpenAI(
        azure_endpoint=azure_openai_endpoint,
        api_key=azure_openai_key,
        api_version="2024-12-01-preview",
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID ã‚’ç”Ÿæˆ
    session_id = f"gpt-demo-{uuid.uuid4().hex[:8]}"

    print(f"ğŸš€ ã‚»ãƒƒã‚·ãƒ§ãƒ³ ID: {session_id}")
    print(f"ğŸ”— Azure OpenAI ãƒ¢ãƒ‡ãƒ«: {azure_openai_model}")
    print(f"ğŸŠ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«: {pool_endpoint[:60]}...")

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ¤å®š
    interactive = "--interactive" in sys.argv or "-i" in sys.argv

    if interactive:
        run_interactive(
            client=client,
            model=azure_openai_model,
            pool_endpoint=pool_endpoint,
            session_id=session_id,
        )
    else:
        run_demo(
            client=client,
            model=azure_openai_model,
            pool_endpoint=pool_endpoint,
            session_id=session_id,
        )

    print(f"\n{'='*60}")
    print("âœ… å®Œäº†ï¼")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
